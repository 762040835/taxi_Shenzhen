{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Stay-Point Detection with RAPIDS (cuDF & cuPy)\n",
    "\n",
    "This notebook implements a highly efficient, GPU-accelerated workflow to identify stay-points from taxi GPS data.\n",
    "\n",
    "**The overall logic is as follows:**\n",
    "\n",
    "1.  **Pre-filter in Database**: Extract only relevant low-velocity GPS points from the database to minimize data transfer and memory footprint.\n",
    "2.  **Load Data to GPU**: Read the pre-filtered data into a cuDF DataFrame.\n",
    "3.  **Identify Segments**: Detect consecutive sequences of low-velocity points by checking the time (`Δt`) and distance (`Δd`) gaps between them. A large gap indicates a new stay segment.\n",
    "4.  **Aggregate Segments**: Group the points by segment and calculate metrics for each potential stay-point (start/end times, duration, centroid location).\n",
    "5.  **Filter by Duration**: Keep only the segments that meet the minimum stay duration threshold (`t_min`).\n",
    "6.  **Persist Results**: Save the final stay-points to a file or database for further analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Parameters & Environment Setup\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:33:09.046673Z",
     "start_time": "2025-10-15T14:33:04.368892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cudf\n",
    "import cupy as cp\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy # For specifying dtype in to_sql\n",
    "import pandas as pd\n",
    "import os\n",
    "from urllib.parse import quote_plus\n",
    "import subprocess\n",
    "import psycopg2\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# parmaeters"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T15:20:13.364670Z",
     "start_time": "2025-10-15T15:20:13.360485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Thresholds for stay-point detection\n",
    "VELOCITY_THRESHOLD_KMH = 1.0   # (v_max) Max speed to be considered \"low-velocity\"\n",
    "TIME_GAP_THRESHOLD_S =120      # (gap_thr/s) Max time gap in seconds between consecutive points in the same stay\n",
    "DISTANCE_GAP_THRESHOLD_M = 100  # (dist_thr/m) Optional: Max distance between points to break a stay segment\n",
    "MIN_STAY_DURATION_S = 600       # (t_min/s) Minimum duration for a sequence of points to be considered a valid stay\n",
    "\n",
    "\n",
    "# Database connection (optional, for writing results)\n",
    "username = 'xuhang.liu'\n",
    "password = 'xuhangLIU@HOMES'\n",
    "hostname = 'homes-database.epfl.ch'\n",
    "port = '30767'\n",
    "dbname = 'Shenzhen_Taxi'\n",
    "password = quote_plus(password)\n",
    "DB_URL = f\"postgresql://{username}:{password}@{hostname}:{port}/{dbname}\"\n"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:59:33.376869Z",
     "start_time": "2025-10-15T14:59:33.371778Z"
    }
   },
   "source": [
    "# --- Custom GPU Haversine Distance Function (replaces cuspatial) ---\n",
    "def haversine_distance_gpu(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in meters between two points \n",
    "    on the earth (specified in decimal degrees) using cupy for GPU acceleration.\n",
    "    \"\"\"\n",
    "    # cupy operations require float64 for precision in trig functions\n",
    "    lon1_rad = cp.radians(lon1.astype(cp.float64))\n",
    "    lat1_rad = cp.radians(lat1.astype(cp.float64))\n",
    "    lon2_rad = cp.radians(lon2.astype(cp.float64))\n",
    "    lat2_rad = cp.radians(lat2.astype(cp.float64))\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    a = cp.sin(dlat / 2)**2 + cp.cos(lat1_rad) * cp.cos(lat2_rad) * cp.sin(dlon / 2)**2\n",
    "    c = 2 * cp.arcsin(cp.sqrt(a))\n",
    "    \n",
    "    # Radius of earth in meters.\n",
    "    R = 6371000\n",
    "    return c * R\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Data Loading & Preprocessing"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:33:24.173120Z",
     "start_time": "2025-10-15T14:33:24.154429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "table_name = \"taxi_data2020_01_01\"\n",
    "OUTPUT_CSV_PATH = os.path.join(os.getcwd(), 'gps_data_01_01.csv')\n",
    "print(f\"当前目录: {os.getcwd()}\")\n",
    "print(f\"输出文件: {OUTPUT_CSV_PATH}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前目录: /home/lxhep/etaxi\n",
      "输出文件: /home/lxhep/etaxi/gps_data_01_01.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:22:13.554218Z",
     "start_time": "2025-10-15T14:05:51.120011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "query = f\"\"\"\n",
    "SELECT\n",
    "    gid, taxiid,\n",
    "    to_char(time, 'YYYY-MM-DD HH24:MI:SS.US') as time,\n",
    "    lon, lat, velocity, angle, passenger, zoneid, validity,\n",
    "    hvalue, \"OSM_edgeid\", \"OSM_distance\"\n",
    "FROM {table_name}\n",
    "WHERE  passenger = 0 AND velocity =0 AND time >= '2020-01-01'\n",
    "ORDER BY taxiid, time\n",
    "\"\"\"\n",
    "\n",
    "conn = psycopg2.connect(DB_URL)\n",
    "cur = conn.cursor()\n",
    "\n",
    "with open(OUTPUT_CSV_PATH, 'w', encoding='utf-8') as f:\n",
    "    cur.copy_expert(f\"COPY ({query}) TO STDOUT WITH CSV HEADER\", f)\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:54:39.326734Z",
     "start_time": "2025-10-15T14:54:38.875681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "INPUT_CSV_PATH = 'gps_data_01_01.csv'\n",
    "\n",
    "gdf_01_01= cudf.read_csv(\n",
    "        INPUT_CSV_PATH,\n",
    "        nrows=1E6,\n",
    "        dtype={\n",
    "            'taxiid': 'str',\n",
    "            'lon': np.float32,\n",
    "            'lat': np.float32,\n",
    "            'angle': np.int16,\n",
    "            'zoneid': np.int32,\n",
    "            'validity': np.int8\n",
    "        },\n",
    "        parse_dates=['time']\n",
    "    )\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T16:16:37.862689Z",
     "start_time": "2025-10-15T16:16:37.775292Z"
    }
   },
   "cell_type": "code",
   "source": "gdf_01_01.iloc[1000]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           gid     taxiid                time         lon        lat  \\\n",
       "1000  79995452  UUUB0C0M7 2020-01-03 06:46:52  114.008827  22.539022   \n",
       "\n",
       "      velocity  angle  passenger  zoneid  validity hvalue  \\\n",
       "1000         0     45          0    1863         1      H   \n",
       "\n",
       "                 OSM_edgeid  OSM_distance           prev_time    prev_lon  \\\n",
       "1000  {380820589,493389662}      6.527811 2020-01-03 06:46:50  114.008827   \n",
       "\n",
       "       prev_lat  dt   dd  grp  \n",
       "1000  22.539022   2  0.0  287  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gid</th>\n",
       "      <th>taxiid</th>\n",
       "      <th>time</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>velocity</th>\n",
       "      <th>angle</th>\n",
       "      <th>passenger</th>\n",
       "      <th>zoneid</th>\n",
       "      <th>validity</th>\n",
       "      <th>hvalue</th>\n",
       "      <th>OSM_edgeid</th>\n",
       "      <th>OSM_distance</th>\n",
       "      <th>prev_time</th>\n",
       "      <th>prev_lon</th>\n",
       "      <th>prev_lat</th>\n",
       "      <th>dt</th>\n",
       "      <th>dd</th>\n",
       "      <th>grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>79995452</td>\n",
       "      <td>UUUB0C0M7</td>\n",
       "      <td>2020-01-03 06:46:52</td>\n",
       "      <td>114.008827</td>\n",
       "      <td>22.539022</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1863</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>{380820589,493389662}</td>\n",
       "      <td>6.527811</td>\n",
       "      <td>2020-01-03 06:46:50</td>\n",
       "      <td>114.008827</td>\n",
       "      <td>22.539022</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T14:57:47.432222Z",
     "start_time": "2025-10-15T14:57:47.322997Z"
    }
   },
   "cell_type": "code",
   "source": "gdf_01_01 = gdf_01_01.dropna()",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# timegap\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T15:19:14.663031Z",
     "start_time": "2025-10-15T15:19:14.060441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not gdf_01_01.empty:\n",
    "    # --- Calculate gaps within each taxi's trajectory ---\n",
    "\n",
    "    # 1. Get the previous point's time and coordinates\n",
    "    # groupby().shift() is a powerful operation to look at the previous record within a group\n",
    "    gdf_01_01['prev_time'] = gdf_01_01.groupby('taxiid')['time'].shift()\n",
    "    gdf_01_01['prev_lon'] = gdf_01_01.groupby('taxiid')['lon'].shift().fillna(0)\n",
    "    gdf_01_01['prev_lat'] = gdf_01_01.groupby('taxiid')['lat'].shift().fillna(0)\n",
    "\n",
    "    # 2. Calculate time gap in seconds\n",
    "    # .fillna() is used for the very first point of each taxi, which has no 'previous' time\n",
    "    gdf_01_01['dt'] = (gdf_01_01['time'] - gdf_01_01['prev_time']).dt.seconds.fillna(99999)\n",
    "\n",
    "    # 3. Calculate distance gap in meters using our custom GPU function\n",
    "    # Haversine distance is the shortest distance between two points on a sphere\n",
    "    gdf_01_01['dd'] = haversine_distance_gpu(\n",
    "       gdf_01_01['lon'], gdf_01_01['lat'], gdf_01_01['prev_lon'], gdf_01_01['prev_lat']\n",
    "    )\n",
    "\n",
    "    print(gdf_01_01.head(10))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gid     taxiid                time         lon        lat  velocity  \\\n",
      "0  3174547  UUUB0C0M7 2020-01-01 00:15:06  114.121605  22.568609         0   \n",
      "1  4055440  UUUB0C0M7 2020-01-01 00:19:12  114.125244  22.566677         0   \n",
      "2  3183345  UUUB0C0M7 2020-01-01 00:19:43  114.125198  22.567152         0   \n",
      "3  3182961  UUUB0C0M7 2020-01-01 00:19:43  114.125198  22.567152         0   \n",
      "4  3190190  UUUB0C0M7 2020-01-01 00:19:58  114.125198  22.567152         0   \n",
      "5  3972098  UUUB0C0M7 2020-01-01 00:20:13  114.125198  22.567152         0   \n",
      "6  4889514  UUUB0C0M7 2020-01-01 00:20:28  114.125198  22.567152         0   \n",
      "7  3978957  UUUB0C0M7 2020-01-01 00:20:28  114.125198  22.567152         0   \n",
      "8  3979415  UUUB0C0M7 2020-01-01 00:20:30  114.125198  22.567152         0   \n",
      "9  5900661  UUUB0C0M7 2020-01-01 00:33:29  114.163345  22.566698         0   \n",
      "\n",
      "   angle  passenger  zoneid  validity hvalue   OSM_edgeid  OSM_distance  \\\n",
      "0     90          0    1205         1      H  {913520745}     47.105614   \n",
      "1     12          0    1206         1      H  {219498397}      5.718987   \n",
      "2    171          0    1206         1      H  {219498397}      3.812511   \n",
      "3    171          0    1206         1      H  {219498397}      3.812511   \n",
      "4    171          0    1206         1      H  {219498397}      3.812511   \n",
      "5    171          0    1206         1      H  {219498397}      3.812511   \n",
      "6    171          0    1206         1      H  {219498397}      3.812511   \n",
      "7    171          0    1206         1      H  {219498397}      3.812511   \n",
      "8    171          0    1206         1      H  {219498397}      3.812511   \n",
      "9      9          0    3126         1      H  {996937216}      8.986453   \n",
      "\n",
      "                       prev_time    prev_lon   prev_lat     dt            dd  \n",
      "0                            NaT    0.000000   0.000000  99999  1.247289e+07  \n",
      "1  2020-01-01 00:15:06.000000000  114.121605  22.568609    246  4.310365e+02  \n",
      "2  2020-01-01 00:19:12.000000000  114.125244  22.566677     31  5.301855e+01  \n",
      "3  2020-01-01 00:19:43.000000000  114.125198  22.567152      0  0.000000e+00  \n",
      "4  2020-01-01 00:19:43.000000000  114.125198  22.567152     15  0.000000e+00  \n",
      "5  2020-01-01 00:19:58.000000000  114.125198  22.567152     15  0.000000e+00  \n",
      "6  2020-01-01 00:20:13.000000000  114.125198  22.567152     15  0.000000e+00  \n",
      "7  2020-01-01 00:20:28.000000000  114.125198  22.567152      0  0.000000e+00  \n",
      "8  2020-01-01 00:20:28.000000000  114.125198  22.567152      2  0.000000e+00  \n",
      "9  2020-01-01 00:20:30.000000000  114.125198  22.567152    779  3.917292e+03  \n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Identify Stay Segments\n",
    "\n",
    "A new stay segment begins when:\n",
    "1. It's the first point for a given taxi.\n",
    "2. The time gap (`dt`) from the previous point exceeds `TIME_GAP_THRESHOLD_S`.\n",
    "3. The distance gap (`dd`) from the previous point exceeds `DISTANCE_GAP_THRESHOLD_M`.\n",
    "\n",
    "We create a boolean flag for these conditions and then use a cumulative sum (`cumsum`) to assign a unique ID (`grp`) to each segment.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T15:20:38.285727Z",
     "start_time": "2025-10-15T15:20:37.875259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not gdf_01_01.empty:\n",
    "    # --- Flag the start of a new segment ---\n",
    "    new_segment_flag = (gdf_01_01['dt'] > TIME_GAP_THRESHOLD_S) | \\\n",
    "                       (gdf_01_01['dd'] > DISTANCE_GAP_THRESHOLD_M) | \\\n",
    "                       (gdf_01_01['prev_time'].isnull()) # The first point for each taxi is always a new segment\n",
    "\n",
    "    # --- Assign a unique ID to each segment ---\n",
    "    # Convert the boolean Series to a cupy array for cumsum\n",
    "    # This is a highly efficient way to create group identifiers\n",
    "    gdf_01_01['grp'] = cp.asarray(new_segment_flag).astype(cp.int32).cumsum()\n",
    "\n",
    "    print(\"Assigned segment IDs to all points.\")\n",
    "    print(gdf_01_01.head(10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned segment IDs to all points.\n",
      "       gid     taxiid                time         lon        lat  velocity  \\\n",
      "0  3174547  UUUB0C0M7 2020-01-01 00:15:06  114.121605  22.568609         0   \n",
      "1  4055440  UUUB0C0M7 2020-01-01 00:19:12  114.125244  22.566677         0   \n",
      "2  3183345  UUUB0C0M7 2020-01-01 00:19:43  114.125198  22.567152         0   \n",
      "3  3182961  UUUB0C0M7 2020-01-01 00:19:43  114.125198  22.567152         0   \n",
      "4  3190190  UUUB0C0M7 2020-01-01 00:19:58  114.125198  22.567152         0   \n",
      "5  3972098  UUUB0C0M7 2020-01-01 00:20:13  114.125198  22.567152         0   \n",
      "6  4889514  UUUB0C0M7 2020-01-01 00:20:28  114.125198  22.567152         0   \n",
      "7  3978957  UUUB0C0M7 2020-01-01 00:20:28  114.125198  22.567152         0   \n",
      "8  3979415  UUUB0C0M7 2020-01-01 00:20:30  114.125198  22.567152         0   \n",
      "9  5900661  UUUB0C0M7 2020-01-01 00:33:29  114.163345  22.566698         0   \n",
      "\n",
      "   angle  passenger  zoneid  validity hvalue   OSM_edgeid  OSM_distance  \\\n",
      "0     90          0    1205         1      H  {913520745}     47.105614   \n",
      "1     12          0    1206         1      H  {219498397}      5.718987   \n",
      "2    171          0    1206         1      H  {219498397}      3.812511   \n",
      "3    171          0    1206         1      H  {219498397}      3.812511   \n",
      "4    171          0    1206         1      H  {219498397}      3.812511   \n",
      "5    171          0    1206         1      H  {219498397}      3.812511   \n",
      "6    171          0    1206         1      H  {219498397}      3.812511   \n",
      "7    171          0    1206         1      H  {219498397}      3.812511   \n",
      "8    171          0    1206         1      H  {219498397}      3.812511   \n",
      "9      9          0    3126         1      H  {996937216}      8.986453   \n",
      "\n",
      "                       prev_time    prev_lon   prev_lat     dt            dd  \\\n",
      "0                            NaT    0.000000   0.000000  99999  1.247289e+07   \n",
      "1  2020-01-01 00:15:06.000000000  114.121605  22.568609    246  4.310365e+02   \n",
      "2  2020-01-01 00:19:12.000000000  114.125244  22.566677     31  5.301855e+01   \n",
      "3  2020-01-01 00:19:43.000000000  114.125198  22.567152      0  0.000000e+00   \n",
      "4  2020-01-01 00:19:43.000000000  114.125198  22.567152     15  0.000000e+00   \n",
      "5  2020-01-01 00:19:58.000000000  114.125198  22.567152     15  0.000000e+00   \n",
      "6  2020-01-01 00:20:13.000000000  114.125198  22.567152     15  0.000000e+00   \n",
      "7  2020-01-01 00:20:28.000000000  114.125198  22.567152      0  0.000000e+00   \n",
      "8  2020-01-01 00:20:28.000000000  114.125198  22.567152      2  0.000000e+00   \n",
      "9  2020-01-01 00:20:30.000000000  114.125198  22.567152    779  3.917292e+03   \n",
      "\n",
      "   grp  \n",
      "0    1  \n",
      "1    2  \n",
      "2    2  \n",
      "3    2  \n",
      "4    2  \n",
      "5    2  \n",
      "6    2  \n",
      "7    2  \n",
      "8    2  \n",
      "9    3  \n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Aggregate Segments to Find Stays\n",
    "\n",
    "Now that each point belongs to a segment (`grp`), we can group by `taxiid` and `grp` to aggregate the data. For each segment, we calculate:\n",
    "- The start and end time.\n",
    "- The average longitude and latitude (to find the centroid).\n",
    "- The number of points in the stay.\n",
    "\n",
    "Finally, we calculate the duration of each segment and filter out those that are shorter than `MIN_STAY_DURATION_S`.\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T15:26:31.042402Z",
     "start_time": "2025-10-15T15:26:30.918313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not gdf_01_01.empty:\n",
    "    # --- Group by segment to create potential stays ---\n",
    "    agg_stays = gdf_01_01.groupby(['taxiid', 'grp']).agg(\n",
    "        start_time=('time', 'min'),\n",
    "        end_time=('time', 'max'),\n",
    "        stay_lon=('lon', 'mean'),\n",
    "        stay_lat=('lat', 'mean'),\n",
    "        points=('taxiid', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    # --- Calculate duration and filter for valid stays ---\n",
    "    agg_stays['duration_s'] = (agg_stays['end_time'] - agg_stays['start_time']).dt.seconds\n",
    "\n",
    "    final_stays = agg_stays[agg_stays['duration_s'] >= MIN_STAY_DURATION_S].copy()\n",
    "    final_stays = final_stays.sort_values(['taxiid', 'start_time'])\n",
    "    print(f\"Found {len(final_stays)} valid stay-points.\")\n",
    "    print(\"Final stay-points DataFrame head:\")\n",
    "    print(final_stays.head(20))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6655 valid stay-points.\n",
      "Final stay-points DataFrame head:\n",
      "           taxiid  grp          start_time            end_time    stay_lon  \\\n",
      "112212  UUUB0C0M7  158 2020-01-02 03:23:09 2020-01-02 03:56:24  114.078497   \n",
      "307     UUUB0C0M7  243 2020-01-02 20:03:06 2020-01-02 20:17:51  114.113434   \n",
      "226268  UUUB0C0M7  258 2020-01-02 23:53:55 2020-01-03 00:08:10  114.032786   \n",
      "267301  UUUB0C0M7  262 2020-01-03 00:44:40 2020-01-03 01:14:24  114.124169   \n",
      "58853   UUUB0C0M7  264 2020-01-03 01:24:39 2020-01-03 01:46:40  114.124214   \n",
      "142251  UUUB0C0M7  272 2020-01-03 02:39:55 2020-01-03 02:50:40  114.078691   \n",
      "262662  UUUB0C0M7  278 2020-01-03 03:29:39 2020-01-03 03:43:25  114.124285   \n",
      "152341  UUUB0C0M7  279 2020-01-03 03:46:10 2020-01-03 04:04:39  114.124304   \n",
      "188232  UUUB0C0M7  380 2020-01-04 03:15:08 2020-01-04 03:30:21  113.810077   \n",
      "228868  UUUB0C0M7  386 2020-01-04 04:34:23 2020-01-04 04:57:53  114.143025   \n",
      "190714  UUUB0C0M7  495 2020-01-05 01:32:16 2020-01-05 01:46:32  114.138767   \n",
      "76457   UUUB0C0M7  618 2020-01-05 21:41:57 2020-01-05 22:04:42  114.136173   \n",
      "45425   UUUB0C0M7  631 2020-01-06 01:15:02 2020-01-06 01:32:17  114.134989   \n",
      "264061  UUUB0C0M7  638 2020-01-06 02:20:35 2020-01-06 02:47:35  114.126456   \n",
      "101116  UUUB0C0M7  663 2020-01-06 09:24:59 2020-01-06 09:39:44  113.917678   \n",
      "169864  UUUB0C0M7  684 2020-01-06 14:59:29 2020-01-06 15:21:59  114.108565   \n",
      "126868  UUUB0C0M7  686 2020-01-06 15:30:59 2020-01-06 15:45:14  114.108453   \n",
      "10795   UUUB0C0M7  756 2020-01-07 12:16:50 2020-01-07 12:26:55  114.116302   \n",
      "93599   UUUB0C0P3  855 2020-01-01 09:06:56 2020-01-01 09:22:19  113.963643   \n",
      "239056  UUUB0C0P3  858 2020-01-01 09:41:49 2020-01-01 09:54:49  113.963645   \n",
      "\n",
      "         stay_lat  points  duration_s  \n",
      "112212  22.533872      63        1995  \n",
      "307     22.534883      16         885  \n",
      "226268  22.570854      24         855  \n",
      "267301  22.554399      47        1784  \n",
      "58853   22.554401      32        1321  \n",
      "142251  22.534077      25         645  \n",
      "262662  22.554441      28         826  \n",
      "152341  22.554442      40        1109  \n",
      "188232  22.627401      26         913  \n",
      "228868  22.556194      47        1410  \n",
      "190714  22.554623      18         856  \n",
      "76457   22.548507      34        1365  \n",
      "45425   22.570342      23        1035  \n",
      "264061  22.547841      57        1620  \n",
      "101116  22.562445      21         885  \n",
      "169864  22.580906      44        1350  \n",
      "126868  22.580926      18         855  \n",
      "10795   22.580355      16         605  \n",
      "93599   22.543613      25         923  \n",
      "239056  22.543611      17         780  \n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T15:29:10.177005Z",
     "start_time": "2025-10-15T15:29:10.170955Z"
    }
   },
   "cell_type": "code",
   "source": "len(final_stays)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6655"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Matching with stations\n"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:14:01.379987Z",
     "start_time": "2025-10-15T17:14:01.376842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from scipy.spatial import cKDTree\n"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:18:00.036280Z",
     "start_time": "2025-10-15T17:18:00.019144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Parameters for Matching ---\n",
    "STATION_CSV_PATH = 'station_information.csv'\n",
    "DISTANCE_THRESHOLD_M = 100  # Threshold in meters to consider a stay as a charging event\n",
    "\n",
    "# --- 1. Load Station Data (on CPU) ---\n",
    "# Create a dummy station file if it doesn't exist for demonstration\n",
    "\n",
    "stations_df = pd.read_csv(STATION_CSV_PATH)\n",
    "# --- 2. Build cKDTree from Station Coordinates (on CPU) ---\n",
    "# This assumes both GPS and station data use the WGS-84 coordinate system.\n",
    "station_coords = stations_df[['longitude', 'latitude']].to_numpy()\n",
    "station_tree = cKDTree(station_coords)\n",
    "print(\"cKDTree built successfully from station data.\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cKDTree built successfully from station data.\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:18:01.904699Z",
     "start_time": "2025-10-15T17:18:01.875267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 3. Query the Tree with Stay-Points ---\n",
    "# Check if the 'final_stays' DataFrame from the previous step exists\n",
    "if not final_stays.empty:\n",
    "\n",
    "\n",
    "    # 3a. Transfer stay-point coordinates from GPU to CPU\n",
    "    stay_coords = final_stays[['stay_lon', 'stay_lat']].to_numpy()\n",
    "\n",
    "    # 3b. Perform the nearest neighbor query using the cKDTree\n",
    "\n",
    "    distances_deg, indices = station_tree.query(stay_coords, k=1)\n",
    "\n",
    "\n",
    "    # 3c. Convert distance from degrees to approximate meters.\n",
    "    # This approximation (1 degree ≈ 111.32 km) is valid for city-scale analysis.\n",
    "    distances_m = distances_deg * 111320\n",
    "\n",
    "    # --- 4. Add Matching Results back to the GPU DataFrame ---\n",
    "\n",
    "    # Transfer the numpy arrays from CPU back to GPU as new cudf Series\n",
    "    final_stays['distance_to_station_m'] = distances_m\n",
    "\n",
    "    # Map the indices from the query result back to the original station_id\n",
    "    station_id_lookup = stations_df['station_id'].to_numpy()\n",
    "    nearest_station_ids = station_id_lookup[indices]\n",
    "    final_stays['nearest_station_id'] = cudf.Series(nearest_station_ids, index=final_stays.index)\n",
    "\n",
    "    # --- 5. Filter for Charging Events based on the distance threshold ---\n",
    "\n",
    "    charging_events = final_stays[final_stays['distance_to_station_m'] <= DISTANCE_THRESHOLD_M].copy()\n",
    "    charging_events = charging_events.sort_values(['taxiid', 'start_time'])\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"\\n'final_stays' DataFrame not found or is empty. Please run the preceding cells to generate stay-points first.\")\n"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:18:13.551933Z",
     "start_time": "2025-10-15T17:18:13.543996Z"
    }
   },
   "cell_type": "code",
   "source": "len(charging_events)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T17:18:17.118653Z",
     "start_time": "2025-10-15T17:18:17.093130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "charging_events.iloc[200]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           taxiid    grp          start_time            end_time    stay_lon  \\\n",
       "144173  UUUB1C1P5  95967 2020-01-05 08:32:27 2020-01-05 09:01:12  113.941949   \n",
       "\n",
       "         stay_lat  points  duration_s  distance_to_station_m  \\\n",
       "144173  22.532894      45        1725              93.619151   \n",
       "\n",
       "        nearest_station_id  \n",
       "144173                1467  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxiid</th>\n",
       "      <th>grp</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>stay_lon</th>\n",
       "      <th>stay_lat</th>\n",
       "      <th>points</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>distance_to_station_m</th>\n",
       "      <th>nearest_station_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144173</th>\n",
       "      <td>UUUB1C1P5</td>\n",
       "      <td>95967</td>\n",
       "      <td>2020-01-05 08:32:27</td>\n",
       "      <td>2020-01-05 09:01:12</td>\n",
       "      <td>113.941949</td>\n",
       "      <td>22.532894</td>\n",
       "      <td>45</td>\n",
       "      <td>1725</td>\n",
       "      <td>93.619151</td>\n",
       "      <td>1467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
